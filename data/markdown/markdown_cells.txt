# 목차

#### 1. EDA (Exploratory Data Analysis)
#### 2. 전처리 및 특성공학
#### 3. 모델링 및 하이퍼파라미터 튜닝
#### 4. 분류성능지표
#### 5. 프로젝트 요약

#### 이 데이터셋은 신용카드 회사의 고객 정보를 포함하고 있습니다. 각 행에는 고객 ID와 나이, 연봉, 결혼 여부, 신용카드 한도, 신용카드 카테고리 등과 같은 다양한 특성이 포함되어 있습니다.

#### 이 프로젝트의 목표는 회사의 신용카드 사용자의 특성 및 소비 형태 등을 모델로 분석하여 미래에 이탈할 고객들을 예측하여, 기업이 마케팅 전략을 맞춤화하고 제품 제공을 최적화할 수 있도록 하는 것입니다.


----

## 1. EDA (Exploratory Data Analysis)
#### 데이터의 이해 및 이상치와 변수 간의 관계 파악

#### 1) 범주형 데이터 확인

#### **평가**
 1. 데이터 정보 확인상 결측치는 발견되지 않았으나, Education_Level (교육 수준), Marital_Status (혼인 여부), Income_Category (수입 구분)에서 "Unknown" 데이터 확인
2. 고객들의 Gender (성별)은 균형이 맞지만, Attrition_Flag (해지 여부)의 데이터는 83.9% 대 16.1%로 불균형이 심하게 난다.
3. Income_Category (수입 구분)에서 대부분의 고객들은 $40,000 이하의 수입을 얻는 것으로 확인
4. Card_Category (카드 구분)에서 대부분의 고객들은 블루 카드를 소지하는 것으로 확인

#### 2) 수치형 데이터 확인

----

## 2. 전처리 및 특성공학
#### "Unknown" 결측치 데이터를 처리하여 데이터를 총 5가지로 나눠서 모델링을 진행하고자한다.
|데이터프레임|df1|df2|df3|df4|df5|
|-|-|-|-|-|-|
|방법|최빈값 |완전삭제|Hot-Deck|Knn기법|결측값사용|
|데이터 수|10,127|7,081|10,127|10,127|10,127|

#### 1) 최빈값
Unknown 데이터를 각각 3개의 범주형 컬럼 ('Education_Level', 'Marital_Status', 'Income_Category' )에 있는 가장 많이있는 값으로 대체

#### 2) 완전삭제
Unknown 데이터를 완전히 삭제

#### 3) Hot-dect 대체
Unknown 대상 변수와 유사성을 가지는 행을 찾아, 결측값을 대체

#### 4) KNN 기법
인접 이웃 수의 가중 또는 가중 평균을 사용하여 Unknown 값을 대체

#### 5) Unknown 데이터 사용
Unknown 데이터를 삭제하지 않고 남겨서 사용

#### 인코딩
#### - 모델을 사용하기 위해 범주형 데이터 인코딩 진행

#### 히트맵 그리기

#### 평가
df1 ~ df5 높은 상관관계 확인

| 항목                    | 최대 상관관계 | 최소 상관관계 |
|-------------------------|--------------|--------------|
| Avg_Open_To_Buy, Credit_Limit | 1.00         | 1.00         |
| Total_Trans_Ct, Total_Trans_Amt | 0.81         | 0.81         |
| Income_Category, Gender   | 0.80         | 0.71         |
| Months_on_book, Customer_Age | 0.79         | 0.79         |
| Avg_Utilization_Ratio, Total_Revolving_Bal | 0.63         | 0.48         |


#### 다중 공선성 검정
VIF 및 공차를 확인하기

[VIF >10, 공차 (Tolerance) < 0.1]

#### 다중공선성 평가
VIF가 높고 공차가 낮은 컬럼 : 'Customer_Age', 'Months_on_book', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Trans_Ct'
| Feature             | 최대 VIF | 최소 VIF | 최대 공차 | 최소 공차 |
|---------------------|---------|---------|---------|---------|
| Credit_Limit        | inf     | inf     | 0.00    | 0.00    |
| Total_Revolving_Bal | inf     | inf     | 0.00    | 0.00    |
| Avg_Open_To_Buy     | inf     | inf     | 0.00    | 0.00    |
| Customer_Age        | 80.17   | 78.09   | 0.01    | 0.01    |
| Months_on_book      | 56.97   | 56.45   | 0.02    | 0.02    |
| Total_Trans_Ct      | 23.86   | 23.68   | 0.04    | 0.04    |
| Card_Category       | 14.95   | 14.50   | 0.07    | 0.07    |
| Total_Amt_Chng_Q4_Q1 | 14.46 | 14.34   | 0.07    | 0.07    |
| Income_Category *     | 12.70   | 8.62    | 0.12    | 0.08    |
| Total_Ct_Chng_Q4_Q1 | 11.84   | 11.82   | 0.08    | 0.08    |


###### * df5 제외


### 데이터 준비 및 스케일링

#### PCA 평가
각 곡선은 df1 부터 df5 까지 13개 차원 분산 중 첫 번째 N개의 구성 요소에 얼마나 많은 분산이 포함되어 있는지 나타냅니다.
1. PCA Standard Scaler - 첫 10개의 구성 요소가 전체 분산의 90%를 포함하고 있습니다.
2. PCA Min-Max - MinMax를 사용하여 스케일링한 후 PCA를 수행하여, 첫 8개의 구성 요소가 전체 분산의 90%를 포함하고 있습니다.
3. PCA Power Transformer - Power Transformer를 사용하여 스케일링한 후 PCA를 수행하여, 첫 10개의 구성 요소가 전체 분산의 90%를 포함하고 있습니다.

#### 각 df에 스케일링 별로 차원 수 줄이기

## 3. 모델링 및 하이퍼파라미터 튜닝


#### SMOTE (Synthetic Minority Over-sampling Technique)
하나의 클래스가 다른 클래스에 비해 상대적으로 적은 상태인 클래스 불균형 문제를 해결하기 위한 오버샘플링 기법 중 하나로, 모델이 다수 클래스에 치우쳐 학습되는 현상을 막기 위해 사용됩니다.

## 4. 분류성능지표


**Accuracy(정확도):** 모델의 전반적인 성능을 나타냅니다.

**Precision(클래스 1에 대한 정밀도):** 클래스 1로 예측한 것 중 실제 클래스 1인 비율입니다.

**Recall(클래스 1에 대한 재현율):** 실제 클래스 1 중에 모델이 클래스 1로 예측한 비율입니다.

**F1-score(평균 F1 점수):** 클래스별 정밀도(Precision)와 재현율(Recall)의 조화 평균입니다. 불균형한 클래스 분포에서 성능을 잘 나타냅니다.

#### **종합 비교 결과**

#### KNN 모델

|     | Accuracy | Precision (Class 0) | Precision (Class 1) | Recall (Class 0) | Recall (Class 1) | F1-score (Class 0) | F1-score (Class 1) |
|-----|----------|----------------------|----------------------|------------------|------------------|----------------------|----------------------|
| df1 | 0.78     | 0.37                 | 0.89                 | 0.48             | 0.83             | 0.42                 | 0.86                 |
| df2 | 0.78     | 0.35                 | 0.90                 | 0.45             | 0.84             | 0.39                 | 0.87                 |
| df3 | 0.78     | 0.37                 | 0.89                 | 0.46             | 0.84             | 0.41                 | 0.86                 |
| df4 | 0.78     | 0.36                 | 0.88                 | 0.44             | 0.85             | 0.40                 | 0.87                 |
| df5 | 0.78     | 0.37                 | 0.88                 | 0.43             | 0.85             | 0.40                 | 0.87                 |

#### RFC 모델

|     | Accuracy | Precision (Class 0) | Precision (Class 1) | Recall (Class 0) | Recall (Class 1) | F1-score (Class 0) | F1-score (Class 1) |
|-----|----------|----------------------|----------------------|------------------|------------------|----------------------|----------------------|
| df1 | 0.92     | 0.75                 | 0.96                 | 0.81             | 0.95             | 0.78                 | 0.95                 |
| df2 | 0.98     | 0.94                 | 0.99                 | 0.94             | 0.98             | 0.93                 | 0.99                 |
| df3 | 0.93     | 0.75                 | 0.96                 | 0.82             | 0.95             | 0.78                 | 0.95                 |
| df4 | 0.92     | 0.73                 | 0.96                 | 0.81             | 0.94             | 0.77                 | 0.95                 |
| df5 | 0.92     | 0.75                 | 0.96                 | 0.82             | 0.94             | 0.78                 | 0.95                 |

#### XGBC 모델

|     | Accuracy | Precision (Class 0) | Precision (Class 1) | Recall (Class 0) | Recall (Class 1) | F1-score (Class 0) | F1-score (Class 1) |
|-----|----------|----------------------|----------------------|------------------|------------------|----------------------|----------------------|
| df1 | 0.93     | 0.77                 | 0.96                 | 0.82             | 0.95             | 0.79                 | 0.96                 |
| df2 | 0.97     | 0.88                 | 0.99                 | 0.93             | 0.98             | 0.91                 | 0.98                 |
| df3 | 0.93     | 0.77                 | 0.96                 | 0.83             | 0.95             | 0.80                 | 0.96                 |
| df4 | 0.93     | 0.75                 | 0.97                 | 0.84             | 0.94             | 0.79                 | 0.95                 |
| df5 | 0.93     | 0.77                 | 0.97                 | 0.84             | 0.95             | 0.80                 | 0.96                 |

#### Logistic Regression 모델

|     | Accuracy | Precision (Class 0) | Precision (Class 1) | Recall (Class 0) | Recall (Class 1) | F1-score (Class 0) | F1-score (Class 1) |
|-----|----------|----------------------|----------------------|------------------|------------------|----------------------|----------------------|
| df1 | 0.72     | 0.33                 | 0.92                 | 0.69             | 0.73             | 0.45                 | 0.81                 |
| df2 | 0.73     | 0.33                 | 0.94                 | 0.72             | 0.73             | 0.45                 | 0.82                 |
| df3 | 0.72     | 0.33                 | 0.92                 | 0.69             | 0.72             | 0.45                 | 0.81                 |
| df4 | 0.72     | 0.33                 | 0.92                 | 0.68             | 0.73             | 0.44                 | 0.81                 |
| df5 | 0.74     | 0.35                 | 0.93                 | 0.70             | 0.75             | 0.47                 | 0.83                 |

#### SVC 모델

|     | Accuracy | Precision (Class 0) | Precision (Class 1) | Recall (Class 0) | Recall (Class 1) | F1-score (Class 0) | F1-score (Class 1) |
|-----|----------|----------------------|----------------------|------------------|------------------|----------------------|----------------------|
| df1 | 0.75     | 0.36                 | 0.91                 | 0.61             | 0.78             | 0.45                 | 0.84                 |
| df2 | 0.78     | 0.37                 | 0.92                 | 0.62             | 0.81             | 0.47                 | 0.86                 |
| df3 | 0.76     | 0.36                 | 0.91                 | 0.61             | 0.79             | 0.45                 | 0.84                 |
| df4 | 0.77     | 0.38                 | 0.91                 | 0.60             | 0.80             | 0.46                 | 0.85                 |
| df5 | 0.81     | 0.45                 | 0.93                 | 0.68             | 0.83             | 0.54                 | 0.88                 |

#### **종합 비교 결과**
- KNN 모델

 df2 에서 가장 높은 Accuracy(0.78)와 F1-score(0.87)를 보임

 Precision 및 Recall 면에서는 일관된 결과

- RFC 모델

 df2 에서 가장 높은 Accuracy(0.98)와 F1-score(0.99)를 보임

 Precision 및 Recall 면에서도 df2 에서 가장 높은 성능

- XGBC 모델

 df2 에서 가장 높은 Accuracy(0.97)와 F1-score(0.98)를 보임

 Precision 및 Recall 면에서도 df2 에서 가장 높은 성능

- Logistic Regression 모델

 df5 에서 가장 높은 Accuracy(0.74)를 보임, 그러나 전체적으로 성능이 다소 낮음

 다른 모델에 비해 Precision 및 Recall 면에서도 상대적으로 성능이 낮음

- SupportVectorMachine 모델

 df5에서 가장 높은 Accuracy(0.81)와 F1-score(0.88)를 df5 보임
 
 Precision 및 Recall 면에서도 df5 데이터 프레임에서 가장 높은 성능

#### **정리**

Random Forest Classifier(RFC)와 Extreme Gradient Boosting Classifier(XGBC) 모델이 df2 데이터 프레임에서 가장 좋은 성능을 보임

Support Vector Classifier(SVC) 모델도 df5 데이터 프레임에서 높은 성능을 보임


#### **과적합확인**
KFold 교차 검증을 통해 모델의 훈련 데이터와 테스트 데이터에 대한 성능을 비교

#### **종합 비교 결과**
| 데이터프레임 | 모델 | AUC   |
|-------------|-------|-------|
| df1         | KNN   | 0.70  |
| -         | RFC   | 0.97  |
| -         | XGBC  | 0.97  |
| -         | LR    | 0.80  |
| -         | SVC   | 0.84  |
| df2         | KNN   | 0.72  |
| -         | RFC   | 0.97  |
| -         | XGBC  | 0.97  |
| -         | LR    | 0.83  |
| -         | SVC   | 0.86  |
| df3         | KNN   | 0.69  |
| -         | RFC   | 0.97  |
| -         | XGBC  | 0.97  |
| -         | LR    | 0.80  |
| -         | SVC   | 0.84  |
| df4         | KNN   | 0.70  |
| -         | RFC   | 0.97  |
| -         | XGBC  | 0.97  |
| -         | LR    | 0.80  |
| -         | SVC   | 0.85  |
| df5         | KNN   | 0.70  |
| -         | RFC   | 0.97  |
| -         | XGBC  | 0.97  |
| -         | LR    | 0.80  |
| -         | SVC   | 0.84  |

AUC(Area Under the ROC Curve)는 모델의 분류 성능을 나타내는 지표로, 1에 가까울수록 좋은 성능을 보입니다.

#### AUC 점수를 비교한 결과는 다음과 같습니다:

**Random Forest (RFC)** , **XGBoost (XGBC)** 모델이 모든 데이터프레임에서 높은 AUC 점수를 보였습니다.

1. Support Vector Machine (SVC) 모델도 모든 데이터프레임에서 높은 AUC 점수를 보여주었습니다.
2. Logistic Regression (LR), K-Nearest Neighbors (KNN) 모델은 모든 데이터프레임에서 RFC, XGBC, SVC 모델에 비해 상대적으로 낮은 AUC 점수를 보였습니다.

따라서 종합적으로 보았을 때, Random Forest와 XGBoost 모델이 가장 높은 AUC 점수를 보였으며, 이 모델들이 데이터프레임에 상관없이 일관된 성능을 보였습니다.

## 5. 프로젝트 요약
#### **목표**
- 신용카드 고객 이탈 예측 모델 개발
- 다양한 결측치 처리 방법을 적용하여 모델 성능 비교

#### **데이터 전처리 방법**
- df1: 최빈값 대체
- df2: 완전삭제
- df3: Hot-Deck 방법 사용
- df4: KNN 기법 사용
- df5: 결측값 사용

#### **모델 성능 비교**
- 평가 지표: 정확도, 정밀도, 재현율, F1 스코어, AUC 점수
- 사용된 모델: KNeighbors, RandomForest, XGBoost, LogisticRegression, SupportVectorMachine

#### **결과**
- 모든 데이터프레임(df1-df5)에서 XGBoost와 RandomForest가 가장 높은 성능을 보였음.
- 혼동행렬에서 정확도, 정밀도, 재현율, F1 스코어가 df2(완전삭제)에서 가장 좋은 성능을 보였음.
- 완전삭제를 통해 누락된 데이터를 처리한 경우에도 모델 성능이 유지되거나 향상되었음.

결론

프로젝트는 결측치 처리에 따른 다섯 가지 방법으로 데이터를 전처리하고, 이를 다섯 가지 모델로 평가한 것이었습니다.
누락된 데이터를 처리하는 방법은 모델 성능에 중요한 영향을 미쳤으며, 주어진 데이터에서는 완전 삭제 방법이 모델 성능을 향상시킬 수 있는 효과적인 방법임을 확인했습니다.
데이터의 전처리에 있어 여러 방법이 있지만 데이터 분석상 신중하게 조사하여 방법을 선택해야 하기에, 각 전처리 방법을 모델로 평가하여 분석할 수 있었습니다.

## 6. 서비스 기획
위의 방법으로 선택된 df2(완전삭제) 데이터와 XGBoost 모델을 활용하여 어떤 요소가 고객의 이탈률에 얼마나 영향을 끼쳤는지를 확인하여 신용카드 회사의 서비스를 개선하고자 합니다.

특성 중요도 결과

| 순위 | 특성 이름                  | 중요도 |
|------|----------------------------|-------|
| 1    | Total_Trans_Amt            | 532   |
| 2    | Total_Amt_Chng_04_Q1      | 425   |
| 3    | Total_Ct_Chng_Q4_Q1       | 372   |
| 4    | Avg_Utilization_Ratio      | 239   |
| 5    | Total_Relationship_Count  | 161   |
| 6    | Contacts_Count_12_mon     | 127   |
| 7    | Dependent_count           | 114   |
| 8    | Education_Level           | 109   |
| 9    | Months_Inactive_12_mon    | 94    |
| 10   | Income_Category           | 84    |

#### **해석**

**1. Total_Trans_Amt (총 거래 금액):**

가장 높은 중요도를 가진 특성으로, 고객의 총 거래 금액이 신용카드 이탈률에 가장 큰 영향을 미칩니다. 거래 금액이 높을수록 이탈 가능성이 낮아질 수 있습니다.


**2. Total_Amt_Chng_04_Q1 (1분기 대비 총 거래 금액 변동):**

1분기 대비 총 거래 금액의 변동이 두 번째로 높은 중요도를 가집니다. 이것은 최근 거래 활동의 변화가 이탈 가능성에 미치는 영향을 나타냅니다.


**3. Total_Ct_Chng_Q4_Q1 (4분기 대비 총 거래 건수 변동):**

4분기 대비 총 거래 건수의 변동이 세 번째로 높은 중요도를 가집니다. 이것은 최근 거래 활동의 변화가 이탈 가능성에 미치는 영향을 나타냅니다.

**4. Avg_Utilization_Ratio (평균 카드 이용률):**
 
평균 카드 이용률로 예를들어 카드 사용금액이 1,000 , 카드 한도 5,000 이면 이용률은 20%로 이다(계산방법 Total_Revolving_Bal / Credit_Limit *100)

신용카드의 평균 이용률이 이탈률에 미치는 영향을 나타냅니다. 이용률이 높을 수록 이탈 가능성이 낮아질 수 있습니다.


**5. Total_Relationship_Count (카드 보유 수):**


고객의 카드 보유 수가 많을수록 이탈할 가능성이 낮아질 수 있습니다.

### **제공 서비스**

#### **1. 고객에게 맞춤형 혜택 제공:**
고객의 총 거래 금액이 매우 중요한 요소임을 고려할 때, 총 거래 금액에 따라 다양한 등급의 혜택을 제공할 수 있습니다.
총 거래 금액에 따라 적립되는 포인트나 현금 환급, 할인 혜택 등을 제공하여 고객들에게 맞춤형 혜택을 제공할 수 있습니다.


#### **2. 거래 활동에 따른 개인화된 마케팅 전략 구성:**
거래 활동 변동 및 총 거래 건수 변동이 이탈 가능성에 큰 영향을 미친다는 것을 고려하여, 고객의 거래 활동에 따른 개인화된 마케팅 전략을 구성할 수 있습니다.
최근 거래 활동이 감소하는 고객에게는 특별한 혜택이나 할인을 제공하여 활동을 유도할 수 있습니다.



#### **3. 낮은 회전 잔액을 가진 고객들에게 신용 한도를 증가시키기:**

카드 이용률 관리 및 교육 프로그램 제공:
평균 카드 이용률이 이탈 가능성에 큰 영향을 미친다는 것을 고려하여, 카드 이용률을 적절히 관리하는 것이 중요합니다.
카드 이용률을 적절히 관리할 수 있는 교육 프로그램을 제공하거나, 카드 이용률이 높은 고객에게는 더 높은 신용 한도를 부여함으로써 해당 고객 그룹이 조직을 떠나는 가능성을 낮출 수 있을 것입니다.

#### **4. 신규 고객 유치를 위한 마케팅 전략:**
카드 보유 수가 이탈 가능성에 영향을 미친다는 것을 고려하여, 신규 고객 유치를 위한 마케팅 전략을 구성할 수 있습니다.
새로운 고객을 유치하기 위해 혜택이나 프로모션을 제공하고, 이를 통해 고객들을 계속 유지하도록 유도할 수 있습니다.

